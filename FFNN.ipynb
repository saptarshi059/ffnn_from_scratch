{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36bb28b-6343-4448-9671-c979c865aa8a",
   "metadata": {},
   "source": [
    "# Network Details & Terminology\n",
    "\n",
    "![neural network notation and terminology](nn.png)\n",
    "\n",
    "## Points to Remember\n",
    "1. **Weights and Biases**\n",
    "\n",
    "- Between any 2 layers $l$ and $(l-1)$, there are $n_l * n_{(l-1)}$ connections. For example, layer $1$ has $n_1 = 3$ nodes and layer $0$ has $n_0 = 2$ nodes. Thus, there are a total of $3 * 2$ connections (each node in $l=1$ has $n_0 = 2$ connections) & corresponding weights. This makes the dimension of the weight matrix, $n_l * n_{(l-1)}$.\n",
    "\n",
    "- Bias vectors are only applied to the hidden and output layers. They have a dimension of $n_l * 1$.\n",
    "\n",
    "3. **Sample Size**\n",
    "\n",
    "- The input $X$ and output matrices, $Z$ and $A$ have dimensions $n_l * m$ where $m$ is the total number of training samples. If we were dealing with a single training instance, i.e., $m=1$, each matrix would just become a column vector. _We structure our matrices like this to make the math easier._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81115dfa-a9a5-499a-869b-d86374194592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literally the ONLY library we need to implement our network!\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ab077-c0b2-435c-89bc-aaae5ab9f40d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Initializing our Weights/Biases acc. to the dimension logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ff782-79ad-48e9-879f-25f859745972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the architecture\n",
    "L = 3\n",
    "n = [2, 3, 3, 1]\n",
    "print(f\"Number of Layers: {L}\")\n",
    "for idx in range(len(n)):\n",
    "    print(f\"Nodes in layer {idx} : {n[idx]}\")\n",
    "\n",
    "# Dimensions of my weight matrices\n",
    "dim_W1 = (n[1], n[0]) # Weights connecting layer 1 & 0\n",
    "dim_W2 = (n[2], n[1]) # Weights connecting layer 2 & 1\n",
    "dim_W3 = (n[3], n[2]) # Weights connecting layer 3 & 2\n",
    "\n",
    "# Randomly initializing my weight matrices\n",
    "W1 = np.random.randn(*dim_W1)\n",
    "W2 = np.random.randn(*dim_W2)\n",
    "W3 = np.random.randn(*dim_W3)\n",
    "\n",
    "# Dimensions of my bias vectors\n",
    "dim_B1 = (n[1], 1)\n",
    "dim_B2 = (n[2], 1)\n",
    "dim_B3 = (n[3], 1)\n",
    "\n",
    "# Randomly initializing my bias vectors\n",
    "B1 = np.random.rand(*dim_B1)\n",
    "B2 = np.random.rand(*dim_B2)\n",
    "B3 = np.random.rand(*dim_B3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb3fe2-30b1-472d-a6fe-58071eeda533",
   "metadata": {},
   "source": [
    "### Moving through the network\n",
    "\n",
    "Any neural network has 2 phases of data manipulation,\n",
    "\n",
    "1. Forward Pass: Sequentially transforming the input data through the network to get the final prediction vector.\n",
    "2. Backward Pass: Computing the gradient of the cost function w.r.t the model parameters & updating the parameters using the calculated gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7a574-879f-4bd8-a35d-68b38fd5de7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Forward Pass\n",
    "\n",
    "![forward pass for one layer example](forward_pass.png)\n",
    "\n",
    "I'll explain forward-pass in 3 steps. \n",
    "1. Show calculations for each hidden node.\n",
    "2. Vectorize them, i.e., packaging everything nicely in vectors/matrices.\n",
    "3. Generalize to $m$ samples.\n",
    "\n",
    "**A. Show calculations for each hidden node.**\n",
    "\n",
    "Each non-input layer node does 2 things,\n",
    "* Multiplies the values of the previous nodes with the corresponding weights & sums it up with the biases. This gives the $Z$ vector output.\n",
    "* Applies a non-linear _activation_ function to the previous sum. This gives the $A$ vector output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01287c94-d71b-46e8-8ac6-4f2f7e8711af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Side note on Activation Functions\n",
    "\n",
    "Without an activation function, the entire network would be a collection of linear transformations without learning anything useful. When choosing a function for our network, we want it to have desirable properties such as being differentiable, having global minimums, etc. Popular choices include ReLU, Sigmoid, TanH, etc. We chose sigmoid for this tutorial.\n",
    "\n",
    "*sigmoid Function*\n",
    "Let $X$ be the input (a vector or a single number). The sigmoid function is then given by,\n",
    "* $sigmoid(X) = 1/(1 + e^{-X})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecbff84-a7de-4113-92fe-4be3b8ba3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec61431-1c3c-4e2a-93a3-2c3c504ae4fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Back to Forward Pass\n",
    "\n",
    "Let $z_1$, $z_2$, and $z_3$ be the _pre-activation_ outputs for each node in the hidden layer above. Additionally, we apply the biases, $0.8, 0.1, 0.3$ respectively. This gives us,\n",
    "\n",
    "* $z_1 = (3 * 2 + 6 * 5) + 0.8 = 36.8$\n",
    "* $z_2 = (4 * 2 + 7 * 5) + 0.1 = 43.1$\n",
    "* $z_3 = (5 * 2 + 8 * 5) + 0.3 = 50.3$\n",
    "\n",
    "Looking at the sum, we see that we're basically just performing this expression, $weight * input + bias$.\n",
    "\n",
    "Let $a_1$, $a_2$, and $a_3$ be the _activated_ outputs for each node in the hidden layer above. This gives us,\n",
    "\n",
    "* $a_1 = sigmoid(36.8) = 1.0$\n",
    "* $a_2 = sigmoid(43.1) = 1.0$\n",
    "* $a_3 = sigmoid(50.3) = 1.0$\n",
    "\n",
    "**B. Vectorize them**\n",
    "\n",
    "While it is possible to do all of these calculations independently, it does not scale well to a large number of weights. Additionally, we're not taking advantage of our GPU's which are specifically designed to be good at handling matrix/vector math. So, let's package everything to address this.\n",
    "\n",
    "Let $X$ be our input vector, $W$ our weight matrix, $B$ the bias vector, $Z$ be our pre-activated output & $A$ our activated output. Thus,\n",
    "\n",
    "* $X = \\begin{bmatrix}\n",
    " 2 \\\\\n",
    " 5\n",
    "\\end{bmatrix}$\n",
    "\n",
    "* $W = \\begin{bmatrix}\n",
    " 3 & 6 \\\\\n",
    " 4 & 7 \\\\\n",
    " 5 & 8 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "* $B = \\begin{bmatrix}\n",
    " 0.8 \\\\\n",
    " 0.1 \\\\\n",
    " 0.3\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\therefore W * X = \n",
    "\\begin{bmatrix}\n",
    " 3 & 6 \\\\\n",
    " 4 & 7 \\\\\n",
    " 5 & 8 \\\\\n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    " 2 \\\\\n",
    " 5\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "(3 * 2 + 6 * 5)\\\\\n",
    "(4 * 2 + 7 * 5)\\\\ \n",
    "(5 * 2 + 8 * 5)\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$W * X + B = \\begin{bmatrix}\n",
    "(3 * 2 + 6 * 5)\\\\\n",
    "(4 * 2 + 7 * 5)\\\\ \n",
    "(5 * 2 + 8 * 5)\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    " 0.8 \\\\\n",
    " 0.1 \\\\\n",
    " 0.3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "(3 * 2 + 6 * 5) + 0.8\\\\\n",
    "(4 * 2 + 7 * 5) + 0.1\\\\ \n",
    "(5 * 2 + 8 * 5) + 0.3\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "36.8 \\\\ 43.1 \\\\ 50.3\n",
    "\\end{bmatrix} = Z$\n",
    "\n",
    "* Applying sigmoid to $Z$, we get,\n",
    "\n",
    "$A = \\begin{bmatrix}\n",
    "sigmoid(36.8) \\\\\n",
    "sigmoid(43.1)\\\\\n",
    "sigmoid(50.3)\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1.0 \\\\\n",
    "1.0 \\\\\n",
    "1.0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "<span style=\"color:green\">_You can see these equations are the same as what we got above!_</span>.\n",
    "\n",
    "In general, we have the following 2 equations between any pair of consecutive nodes,\n",
    "\n",
    "$Z_l = W_l * A_{l-1} + B_l$ and $A_l = activation(Z_l)$\n",
    "\n",
    "**C. Generalize to $m$ samples.**\n",
    "\n",
    "Whatever we did above, was for a single input or *1 sample*. We usually deal with much more samples when training our network. The nice thing is, we don't really have to edit much to extend this idea to $m$ samples since we're taking advantage of **matrix multiplication**.\n",
    "\n",
    "Say, our input is now, $X = \\begin{bmatrix}\n",
    "2 & -1 & 7 \\\\\n",
    "5 & -3 & 7 \\\\\n",
    "\\end{bmatrix}$, i.e., we now have 2 more samples alongside our original $\\begin{bmatrix}2 \\\\ 5\\end{bmatrix}$.\n",
    "\n",
    "$X$ has a dimension of $2 * 3$ now. See how easily it aligns with the above equations? The weight matrix has a dimension of $3 * 2$. Thus, the resultant matrix will have a dimension of: $(3 * 2) * (2 * 3) = (3 * 3)$. The bias vector is just repeated 3 times (broadcasted) to become a $(3 * 3)$ matrix as well. This shows how easily we can extend these calculations to $m = 3, 10, \\ldots$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31507e1e-7f69-41bc-8d51-4781adeb7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed-forward layer-by-layer\n",
    "def feed_forward(X):\n",
    "    # Layer 1 calculations\n",
    "    Z1 = W1 @ X + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    # Layer 2 calculations\n",
    "    Z2 = W2 @ A1 + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    # Layer 3 calculations\n",
    "    Z3 = W3 @ A2 + B3\n",
    "    A3 = sigmoid(Z3) # y_hat (final prediction)\n",
    "\n",
    "    # Returning the activations & weights since we need them for during our derivative calculations.\n",
    "    activations = {\"A1\": A1, \"A2\": A2}\n",
    "    weights = {\"W1\": W1, \"W2\": W2, \"W3\": W3}\n",
    "    \n",
    "    return A3, activations, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7587cf-199b-443e-a0bf-bd07d1b28ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### So how did we do? - Loss functions\n",
    "\n",
    "To gauge how well our network is doing, we compute a _loss_ function which tells us how far the network predictions are from the true values. There are several functions we can use, depending on the task. However, since we are dealing with a 2-class problem, **binary cross-entropy** is a good choice for such problems.\n",
    "\n",
    "_Cost v/s Loss_: While they are used interchangeably, _cost_ measures how well the network is doing w.r.t **ALL** training samples while _loss_ is measured on a per sample basis.\n",
    "\n",
    "Let $\\hat{y}$ be the network prediction for a given sample whose true class is $y$. The BCE loss is then given by,\n",
    "\n",
    "![Binary Cross Entropy](bce.png)\n",
    "\n",
    "If $Y$ is the true output vector & $\\hat{Y}$ is the prediction probability vector, \n",
    "\n",
    "The BCE **cost** is then given by, \n",
    "\n",
    "$C_{BCE} (\\hat{Y}, Y) =  -1/m * [Y * \\log\\hat{Y} + (1 - Y)*\\log(1-\\hat{Y})]$\n",
    "\n",
    "i.e., we're simply just taking an average across all the predictions. We apply a negative sign in front of the expression to turn negative log values positive.\n",
    "\n",
    "Let's work through an example & then code it up! Say we have the following, \n",
    "\n",
    "$Y = \\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\end{bmatrix}$ $\\hat{Y} = \\begin{bmatrix}0.7 \\\\ 0.2 \\\\ 0.9 \\end{bmatrix}$\n",
    "\n",
    "First part of the equation gives us, \n",
    "\n",
    "$Y * \\log(\\hat{Y}) = \\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\end{bmatrix} * \\log{\\begin{bmatrix}0.7 \\\\ 0.2 \\\\ 0.9 \\end{bmatrix}} = \\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\end{bmatrix} * \\begin{bmatrix}\\log{0.7} \\\\ \\log{0.2} \\\\ \\log{0.9} \\end{bmatrix} = \\begin{bmatrix}\\log{0.7} \\\\ \\log{0.2} \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "**Notice here that we just did element-wise multiplication rather than matrix multiplication as we ultimately want a single number representing the loss.**\n",
    "\n",
    "Second part of the equation gives us (we **broadcast** 1 to align with the vectors),\n",
    "\n",
    "$(1 - Y) * \\log(1 - \\hat{Y}) = \\left( \\begin{bmatrix}1 \\\\ 1 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\end{bmatrix} \\right) * \\log{\\left( \\begin{bmatrix}1 \\\\ 1 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix}0.7 \\\\ 0.2 \\\\ 0.9 \\end{bmatrix} \\right)} = \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} * \\log{\\left( \\begin{bmatrix}(1-0.7) \\\\ (1-0.2) \\\\ (1-0.9) \\end{bmatrix} \\right)} = \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} * \\left( \\begin{bmatrix}\\log{(1-0.7)} \\\\ \\log{(1-0.2)} \\\\ \\log{(1-0.9)} \\end{bmatrix} \\right) = \\begin{bmatrix}0 \\\\ 0 \\\\ \\log{(1-0.9)} \\end{bmatrix}$\n",
    "\n",
    "Adding the two, we get, \n",
    "\n",
    "$\\begin{bmatrix}\\log{0.7} \\\\ \\log{0.2} \\\\ 0 \\end{bmatrix} + \\begin{bmatrix}0 \\\\ 0 \\\\ \\log{(1-0.9)} \\end{bmatrix} = \\begin{bmatrix}\\log{0.7} \\\\ \\log{0.2} \\\\ \\log{(1-0.9)} \\end{bmatrix} = -[\\log{0.7} + \\log{0.2} + \\log{(1-0.9)}]/3$ (We're taking an average of the elements and prepending the negative sign). \n",
    "\n",
    "This is the exact same value we would get if we did cross-entropy loss for each sample. Example,\n",
    "\n",
    "$-([1 * \\log{0.7} + (1 - 1) * \\log{(1 - 0.7)}] + $\n",
    "\n",
    "$[1 * \\log{0.2} + (1 - 1) * \\log{(1 - 0.2)}] + $\n",
    "\n",
    "$[0 * \\log{0.9} + (1 - 0) * \\log{(1 - 0.9)}])/3 = -[\\log{0.7} + \\log{0.2} + \\log{(1 - 0.9)}]/3$\n",
    "\n",
    "This again illustrates the interplay between vectors and individual equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555febf-aae5-4b1a-948e-17e81fe8c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(y_true: np.ndarray, y_pred:np.ndarray, epsilon: float = 1e-12) -> float:\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    '''\n",
    "    One way to implement it is using matrix multiplication - This will give us the final sum. But we need to explicitly divide by num. of samples to get the mean.\n",
    "    loss = -(y_true @ np.log(y_pred) + (1 - y_true) @ np.log(1 - y_pred))/y_true.shape[0]\n",
    "    '''\n",
    "    \n",
    "    # Another equivalent way (using element-wise multiplication: This will give us individual vectors that need to be summed)\n",
    "    loss = -np.mean(y_true*np.log(y_pred) + (1 - y_true)*np.log(1 - y_pred))\n",
    "\n",
    "    '''\n",
    "    Sometimes loss1 might not be equal to loss2. Although they are both equivalent formulations, matrix multiplication sometimes\n",
    "    introduces some rounding errors. But it is negligible to be bothered about.\n",
    "    '''\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353e54f-29b6-4aa2-871b-894c95edbae5",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "Finally, we concluded the forward-pass &#x1F601; Now for the actual challenging part, backprop &#x1F61F; This is the phase where we tune our model parameters (weights & biases) to get optimal values. We do this by taking the gradient of the cost function, w.r.t. each model parameter. The gradient w.r.t a given parameter tells us if we need to increase or decrease its value to reduce the cost. For example, if $\\frac{\\partial C}{\\partial w} = 2$, it means changing $w$ by $\\partial w$ will increase $C$ by $2 * \\partial w$. As such, we will need to reduce the value of $w$ to decrease $C$.\n",
    "\n",
    "The cost $C$ is a function of $\\hat{Y}$ and $Y$. While the latter is a constant (just the labels), $\\hat{Y}$ is the prediction vector which is essentially a function of all network parameters ($w_{11}, b_{11} \\ldots$). However, taking derivatives w.r.t each, 1-by-1 would be computationally infeasible. As such, we employ matrix tricks like we've done before. This means, in our case, there are _3 weights ($W_1, W_2, W_3$) & 3 biases ($B_1, B_2, B_3$)_ we need to deal with.\n",
    "\n",
    "As we have 3 weights & 3 biases or **6 parameters**, we need **6 partial derivatives**: $\\Bigl[ \\frac{\\partial C}{\\partial W_1}, \\frac{\\partial C}{\\partial W_2}, \\frac{\\partial C}{\\partial W_3}, \\frac{\\partial C}{\\partial B_1}, \\frac{\\partial C}{\\partial B_2}, \\frac{\\partial C}{\\partial B_3} \\Bigr]$.\n",
    "\n",
    "<span style=\"color:blue\">Why partial derivatives?</span>\n",
    "Ans: Partial derivatives allow us to isolate the terms of interest (in our case the 6 above) by treating everything else as constants.\n",
    "\n",
    "The following is the full chain of partial derivatives that we need to consider. We'll work through each partial derivative & code them up immediately. You will see that it makes more sense to work backwards from the last to first layer to get these values (another reason why its called _backprop_).\n",
    "\n",
    "![full chain of derivatives](chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dec03-5070-4ef4-9174-5ed34d18a1e9",
   "metadata": {},
   "source": [
    "#### Partial Derivatives coming from layer 3\n",
    "\n",
    "![layer 3 derivatives](layer3.png)\n",
    "\n",
    "To get $\\frac{\\partial C}{\\partial W_3}$ and $\\frac{\\partial C}{\\partial B_3}$, we apply the multiplication (chain) rule along the <span style=\"color:orange\">orange</span> path to get the partial derivatives.\n",
    "\n",
    "For instance, $\\frac{\\partial C}{\\partial W_3} =  \\frac{\\partial C}{\\partial A_3} * \\frac{\\partial A_3}{\\partial Z_3} * \\frac{\\partial Z_3}{\\partial W_3}$\n",
    "\n",
    "Let's solve each part of the above equation one-by-one.\n",
    "\n",
    "$C = -1/m [Y*\\log{A_3} + (1 - Y) * \\log{(1-A_3)}]$ (remember, $\\hat{Y}$ and $A_3$ are equivalent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b29b55-a648-47f8-b64c-d87bebb1d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_layer_3(y_hat, Y, activations):\n",
    "    dc_dW3 = activations[\"A2\"] @ ((1/Y.shape[1]) * (y_hat - Y)).T\n",
    "    dc_dB3 = np.sum(((1/Y.shape[1]) * (y_hat - Y)), axis=1, keepdims=True)\n",
    "    return dc_dW3, dc_dB3\n",
    "\n",
    "def compute_gradient_layer_2(y_hat, Y, weights, activations):\n",
    "    s1 = ((1/Y.shape[1]) * (y_hat - Y)) \n",
    "    s2 = weights[\"W3\"]\n",
    "    s3 = s1.T @ s2\n",
    "    s4 = activations[\"A2\"] @ s3\n",
    "    s5 = (1 - activations[\"A2\"])\n",
    "    s6 = s4 @ s5\n",
    "    dc_dW2 = s6 @ activations[\"A1\"].T\n",
    "    dc_dB2 = np.sum(s6, axis=1, keepdims=True)\n",
    "    return dc_dW2, dc_dB2\n",
    "\n",
    "def compute_gradient_layer_1(y_hat, Y, weights, activations):\n",
    "    s1 = ((1/Y.shape[1]) * (y_hat - Y)) \n",
    "    s2 = weights[\"W3\"]\n",
    "    s3 = s1.T @ s2\n",
    "    s4 = activations[\"A2\"] @ s3\n",
    "    s5 = (1 - activations[\"A2\"])\n",
    "    s6 = s4 @ s5\n",
    "    s7 = s6.T @ weights[\"W2\"]\n",
    "    s8 = s7.T * activations[\"A1\"]\n",
    "    s9 = (1 - activations[\"A1\"])\n",
    "    s10 = s8 * s9\n",
    "    dc_dW1 = s10 @ X.T\n",
    "    dc_dB1 = np.sum(s10, axis=1, keepdims=True)\n",
    "    return dc_dW1, dc_dB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2cb66-f620-40b3-b489-b002ff8b8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "A0, Y = prepare_data()\n",
    "y_hat, activations, weights = feed_forward(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222ec9e-237e-4f9d-83ae-dd40806721da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    X = np.array([\n",
    "    [150, 70],\n",
    "    [254, 73],\n",
    "    [312, 68],\n",
    "    [120, 60],\n",
    "    [154, 61],\n",
    "    [212, 65],\n",
    "    [216, 67],\n",
    "    [145, 67],\n",
    "    [184, 64],\n",
    "    [130, 69]\n",
    "])\n",
    "\n",
    "    A0 = X.T\n",
    "\n",
    "    y = np.array([\n",
    "    0,\n",
    "    1, \n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0\n",
    "])\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # we need to reshape to a n^[3] x m matrix\n",
    "    Y = y.reshape(n[3], m)\n",
    "    return A0, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8826cc-df3f-4c06-b55b-04ebd506fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0db2e-77b3-4c78-a57b-9c92bc750493",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"... Running epoch {epoch} ...\")\n",
    "\n",
    "    # Forward pass\n",
    "    y_hat, activations, weights = feed_forward(A0)\n",
    "    loss = bce_loss(Y, y_hat)\n",
    "    \n",
    "    costs.append(loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # Gradient compute\n",
    "    dc_dW3, dc_dB3 = compute_gradient_layer_3(y_hat, Y, activations)\n",
    "    dc_dW2, dc_dB2 = compute_gradient_layer_2(y_hat, Y, weights, activations)\n",
    "    dc_dW1, dc_dB1 = compute_gradient_layer_1(y_hat, Y, weights, activations)\n",
    "\n",
    "    # Backprop\n",
    "    W3 = W3 - learning_rate * dc_dW3\n",
    "    W2 = W2 - learning_rate * dc_dW2\n",
    "    W1 = W1 - learning_rate * dc_dW1\n",
    "\n",
    "    B3 = B3 - learning_rate * dc_dB3\n",
    "    B2 = B2 - learning_rate * dc_dB2\n",
    "    B1 = B1 - learning_rate * dc_dB1\n",
    "\n",
    "    print(f\"Cost for epoch {epoch} : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad81f9d-961c-4128-bd62-5bf08613b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explain why we didn't do softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
